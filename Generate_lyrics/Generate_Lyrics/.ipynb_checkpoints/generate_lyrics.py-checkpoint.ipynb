{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#一.读取数据\n",
    "def load_data(fname):\n",
    "    with open(fname , 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    data = text.split()\n",
    "    return data\n",
    "\n",
    "text = load_data('data/split.txt')\n",
    "print(\"前十个词：{}\".format(text[:10]))\n",
    "\n",
    "#二.数据预处理\n",
    "#构造词典及映射\n",
    "vocab = set(text) #set() 函数创建一个无序不重复元素集，可进行关系测试，删除重复数据\n",
    "vocab_to_int = {w : idx for (idx , w) in enumerate(vocab)}  #enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。\n",
    "int_to_vocab = {idx : w for (idx , w) in enumerate(vocab)}\n",
    "\n",
    "print('Total words: {}'.format(len(text)))\n",
    "print('Vocab size: {}'.format(len(vocab)))\n",
    "\n",
    "#转换文本为整数\n",
    "int_text = [vocab_to_int[w] for w in text]\n",
    "print(\"int_text:\" , int_text)\n",
    "\n",
    "#三.构建网络\n",
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # Check TensorFlow Version\n",
    "# assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer'\n",
    "# print('TensorFlow版本: {}'.format(tf.__version__))\n",
    "#\n",
    "# # Check for a GPU\n",
    "# if not tf.test.gpu_device_name():\n",
    "#     warnings.warn('未发现GPU，请使用GPU进行训练！')\n",
    "# else:\n",
    "#     print('默认GPU设备: {}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "#输入层\n",
    "def get_input():\n",
    "    inputs = tf.placeholder(tf.int32 , [None , None] , name = \"inputs\")\n",
    "    targets = tf.placeholder(tf.int32 , [None , None] , name = \"targets\")\n",
    "    learning_rate = tf.placeholder(tf.float32 , name = \"learning_rate\")\n",
    "    return inputs , targets , learning_rate\n",
    "\n",
    "#RNN cell\n",
    "def get_init_cell(batch_size , rnn_size):\n",
    "    #rnn_size为RNN隐层神经元个数\n",
    "    lstm = rnn.BasicLSTMCell(rnn_size)\n",
    "    cell = rnn.MultiRNNCell([lstm]) #https://www.leiphone.com/news/201709/QJAIUzp0LAgkF45J.html\n",
    "\n",
    "    initial_state = cell.zero_state(batch_size , tf.float32) #返回[batch_size, len(cells)]这个函数只是用来生成初始化值的\n",
    "    initial_state = tf.identity(initial_state , \"initial_state\") #它返回一个和输入的 tensor 大小和数值都一样的 tensor ,类似于 y=x 操作\n",
    "    return cell , initial_state\n",
    "\n",
    "#word_embedding\n",
    "def get_embed(input_data , vocab_size , embed_dim):\n",
    "    #单词太多需要embedding\n",
    "    # input_data: 输入的tensor\n",
    "    # vocab_size: 词汇表大小\n",
    "    # embed_dim: 嵌入维度\n",
    "    embedding = tf.Variable(tf.random_uniform([vocab_size, embed_dim], -1, 1))\n",
    "    embed = tf.nn.embedding_lookup(embedding, input_data) #embedding_lookup（params, ids）函数的用法主要是选取一个张量里面索引对应的元素。params可以是张量也可以是数组等，id就是对应的索引。\n",
    "\n",
    "    return embed\n",
    "\n",
    "#Build RNN\n",
    "def build_rnn(cell , inputs):\n",
    "    #构建RNN模型\n",
    "    # cell: RNN单元\n",
    "    # inputs: 输入的batch\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(cell, inputs, dtype=tf.float32) #output与h其实为一样的，需要将output进行其他操作才能得到真正输出\n",
    "\n",
    "    final_state = tf.identity(final_state, 'final_state')\n",
    "    return outputs, final_state\n",
    "\n",
    "#Build Neural Network\n",
    "def build_nn(cell , rnn_size , input_data , vocab_size , embed_dim):\n",
    "    '''\n",
    "       构建神经网络，将RNN层与全连接层相连\n",
    "\n",
    "       参数:\n",
    "       ---\n",
    "       cell: RNN单元\n",
    "       rnn_size: RNN隐层结点数量\n",
    "       input_data: input tensor\n",
    "       vocab_size\n",
    "       embed_dim: 嵌入层大小\n",
    "       '''\n",
    "    embed = get_embed(input_data , vocab_size , embed_dim)\n",
    "    outputs , final_state = build_rnn(cell , embed)\n",
    "\n",
    "    logits = tf.contrib.layers.fully_connected(outputs , vocab_size , activation_fn = None)\n",
    "\n",
    "    return logits , final_state\n",
    "\n",
    "#构造batch\n",
    "    #\n",
    "    # 构造batch\n",
    "    # 在这里，我们将采用以下方式进行batch的构造，如果我们有一个1-20的序列，传入参数batch_size=3, seq_length=2的话，希望返回以下一个四维的向量。\n",
    "    #\n",
    "    # 分为了三个batch，每个batch中包含了输入和对应的目标输出。 get_batches([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 3, 2)\n",
    "    #\n",
    "    # First Batch\n",
    "    # [\n",
    "    #\n",
    "    # Batch of Input\n",
    "    # [[ 1  2], [ 7  8], [13 14]]\n",
    "    # # Batch of targets\n",
    "    # [[ 2  3], [ 8  9], [14 15]]\n",
    "    # ]\n",
    "    #\n",
    "    # Second Batch\n",
    "    # [\n",
    "    #\n",
    "    # # Batch of Input\n",
    "    # [[ 3  4], [ 9 10], [15 16]]\n",
    "    # # Batch of targets\n",
    "    # [[ 4  5], [10 11], [16 17]]\n",
    "    # ]\n",
    "    #\n",
    "    # Third Batch\n",
    "    # [\n",
    "    #\n",
    "    # # Batch of Input\n",
    "    # [[ 5  6], [11 12], [17 18]]\n",
    "    # # Batch of targets\n",
    "    # [[ 6  7], [12 13], [18  1]]\n",
    "    # ] ]\n",
    "def get_batches(int_text, batch_size, seq_length):\n",
    "    '''\n",
    "    构造batch\n",
    "    '''\n",
    "    batch = batch_size * seq_length\n",
    "    n_batch = len(int_text) // batch\n",
    "\n",
    "    int_text = np.array(int_text[:batch * n_batch])  # 保留能构成完整batch的数量\n",
    "\n",
    "    int_text_targets = np.zeros_like(int_text)\n",
    "    int_text_targets[:-1], int_text_targets[-1] = int_text[1:], int_text[0]\n",
    "\n",
    "    # 切分\n",
    "    x = np.split(int_text.reshape(batch_size, -1), n_batch, -1)\n",
    "    y = np.split(int_text_targets.reshape(batch_size, -1), n_batch, -1)\n",
    "\n",
    "    return np.stack((x, y), axis=1)  # 组合\n",
    "\n",
    "#四.模型训练\n",
    "num_epochs = 1000\n",
    "batch_size = 64\n",
    "rnn_size = 512\n",
    "embed_dim = 200 #Embedding Dimension Size\n",
    "seq_length = 20\n",
    "learning_rate = 0.0001\n",
    "show_every_n_batches = 100\n",
    "loss_array = []\n",
    "\n",
    "from tensorflow.contrib import seq2seq\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    vocab_size = len(int_to_vocab)\n",
    "    input_text , targets , lr = get_input() #输入tensor\n",
    "    input_data_shape = tf.shape(input_text)\n",
    "\n",
    "    #初始化RNN\n",
    "    cell , initial_state = get_init_cell(input_data_shape[0] , rnn_size) #input_data_shape[0]为mini_batch的size\n",
    "    logits , final_state = build_nn(cell , rnn_size , input_text , vocab_size , embed_dim)\n",
    "\n",
    "    #计算softmax层概率\n",
    "    probs = tf.nn.softmax(logits , name = \"probs\")\n",
    "\n",
    "    #损失函数\n",
    "    cost = seq2seq.sequence_loss(logits , targets , tf.ones([input_data_shape[0] , input_data_shape[1]]))\n",
    "\n",
    "    #优化函数\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "    #梯度裁剪\n",
    "    gradients = optimizer.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad , -1. , 1.), var) for grad , var in gradients if grad is not None]\n",
    "    train_op = optimizer.apply_gradients(capped_gradients)\n",
    "\n",
    "    #获取batch\n",
    "    batches = get_batches(int_text , batch_size , seq_length)\n",
    "    save_dir = './save'\n",
    "\n",
    "    with tf.Session(graph = train_graph) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            state = sess.run(initial_state , {input_text : batches[0][0]})\n",
    "\n",
    "            for batch_i , (x , y) in enumerate(batches):\n",
    "                feed = {\n",
    "                    input_text : x ,\n",
    "                    targets : y ,\n",
    "                    initial_state : state ,\n",
    "                    lr : learning_rate\n",
    "                }\n",
    "                train_loss , state , _ = sess.run([cost , final_state , train_op] , feed)\n",
    "                loss_array.append(train_loss)\n",
    "\n",
    "                # 每训练一定阶段对结果进行打印\n",
    "                if (epoch * len(batches) + batch_i) % show_every_n_batches == 0:\n",
    "                    print('Epoch {:>3} Batch {:>4}/{}   train_loss = {:.3f}'.format(\n",
    "                        epoch,\n",
    "                        batch_i,\n",
    "                        len(batches),\n",
    "                        train_loss))\n",
    "\n",
    "        #绘制损失图\n",
    "        x_axis = range(len(loss_array))\n",
    "        plt.plot(x_axis, loss_array)\n",
    "        plt.title('loss for each batch')\n",
    "        plt.show()\n",
    "        # 保存模型\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(sess, save_dir)\n",
    "        print('Model Trained and Saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3Xl8VOW9x/HPLyshgbAkIJuAhkUUQYyAS1EUUcSrdlFpbd2qtreb2l692Fp3K225Vr31ai1aa2vVurRWxX0DsSIBZA97ZCdBIAlL9uf+MSdxgGQyIbOcSb7v12tenDnrN5nhl2eeec455pxDREQSR1K8A4iISMuocIuIJBgVbhGRBKPCLSKSYFS4RUQSjAq3iEiCUeGWA5hZkZlNiNGxMszsFTMrNbPnY3HMw9GS34mZXWlmH0U7k3csZ2Z5sTiW+IsKt8TTN4CeQHfn3MXxDhNvZnaGmW2Kdw7xPxVuiaf+wCrnXE1LNzSzlCjkEUkIKtzSJDNLN7MHzGyL93jAzNK9ZTlm9qqZ7TaznWY228ySvGX/bWabzazczFaa2VmN7PtO4DbgUjPbY2bfNbMkM7vVzD43s2Ize8rMsr31B3hdA981sw3Ae01kPt/MPvNyfWxmxwctm2pma71cy83sqwdte62ZrQhaPipo8UgzW+x16zxnZh1C/+rs9966hcE/v5ldFXSMdWb2PW9+JvA60Nv7fewxs95mlmxmPw/KPd/M+gUda4KZrfZ+3ofNzELkkrbCOaeHHg0PoAiY4E3fBXwC9ABygY+Bu71l9wGPAqne4yuAAUOAjUBvb70BwNFNHOsO4K9Bz68G1gBHAVnAS8BfgvbjgKeATCCjkf2dABQDY4Bk4Arv50n3ll8M9CbQYLkU2Av0Clq2GTjJ+znygP5Bv5NPvW27ASuA7zfxM10J1AA3er+XS4FSoJu3fDJwtHeM04F9wChv2RnApoP2dxOwxPu9GjCCQNcS3u/jVaALcCRQApwb7/eQHtF/qMUtoVwG3OWcK3bOlQB3At/xllUDvQgUt2rn3GwXqCa1QDowzMxSnXNFzrm1LTje/c65dc65PcAtwJSDukXucM7tdc7tb2T764A/OOfmOudqnXN/BiqBsQDOueedc1ucc3XOueeA1cBob9trgN845+a5gDXOuc+D9v2Qt+1O4BVgZIifoxh4wPu9PAesJFCwcc695pxb6x3jQ+AtAn/0mnINcKtzbqW3zSLn3BdBy6c553Y75zYA7zeTS9oIFW4JpTcQXLw+9+YB/JZA6/gt7yP/VADn3BrgBgKt6WIze9bMehOexo6XQuALzHobQ2zfH/iZ122w28x2A/3qM5vZ5UHdKLuB44Acb9t+QKg/MNuCpvcR+ETQlM3eH7Hgn6M+wyQz+8TrXtoNnBeUoTGRzCVthAq3hLKFQDGsd6Q3D+dcuXPuZ865o4ALgJ/W9+U65/7mnDvN29YBv27F8WqA7UHzQl3OciNwr3OuS9Cjo3PuGTPrD/wR+BGBroYuwFIC3Q/12x4dZs7m9Dmor/lIYIv3/cCLwHSgp5dhZlCGxn62SOaSNkKFW0J5BrjVzHLNLIfAl4l/hYYvAfO8AlVKoIukzsyGmNmZXpGqAPYDdS043o1mNtDMsoBfAc+58Eed/BH4vpmNsYBMM5tsZp0I9Is7Av3AmNlVBFrc9WYA/2VmJ3rb5nnF/nD0AH5iZqlmdjFwDIECnUagG6kEqDGzScDEoO22A93rv5ANynW3mQ3ych1vZt0PM5e0ERpSJaHcA3QGFnvPn/fmAQwCfk/gS8tdwP855973RnFMI1Csqgl8oXldmMd7gkCXwiygA/Am8ONwwzrnCszsWi/XIAJ/ND4CZjnnlpvZ/wD/JvCH5ClgTtC2z3sF8W9AHwJfSH6HA7tuwjXXO/4OAsX4G/X90mb2E+DvBAr4K8C/gjIUmtkzwDozSwaGAfd7675FoEulEDhgNIy0P3ZgV5yIiPidukpERBKMCreISIJR4RYRSTAq3CIiCSYqo0pycnLcgAEDorFrEZE2af78+Tucc7nhrBuVwj1gwAAKCgqisWsRkTbJzMIeeqquEhGRBKPCLSKSYFS4RUQSjAq3iEiCUeEWEUkwKtwiIglGhVtEJMH4qnA/9O5qPlxVEu8YIiK+5qvC/eiHa/lotQq3iEgovircaSlJVNfq+uAiIqH4qnCnJidRVRvuXa5ERNonXxXutOQkqmpUuEVEQvFV4U5NNhVuEZFm+KpwJyUZtboHpohISP4q3Gagui0iEpKvCrcBdWpxi4iE5KvCnWSG6raISGi+KtxmanGLiDTHZ4XbqFPdFhEJyVeFO8lA306KiITms8KtFreISHN8VbjVxy0i0jyfFW6NKhERaY6/CjdqcYuINMdXhTvw5aSIiITis8JtanGLiDTDV4XbDOp0cUARkZB8VrgNp3HcIiIh+apwJxkaxy0i0gxfFW7DcOrjFhEJyVeFOykJjeMWEWmGrwq3oVElIiLN8Vfh1g1wRESaFVbhNrMbzWyZmS01s2fMrENUwugiUyIizWq2cJtZH+AnQL5z7jggGZgSjTBm6MtJEZFmhNtVkgJkmFkK0BHYEpUwusiUiEizmi3czrnNwHRgA7AVKHXOvRWNMLrIlIhI88LpKukKXAgMBHoDmWb27UbWu87MCsysoKSk5LDC6NZlIiLNC6erZAKw3jlX4pyrBl4CTjl4JefcY865fOdcfm5u7uGFUR+3iEizwincG4CxZtbRzAw4C1gRjTCBLyejsWcRkbYjnD7uucALwAJgibfNY1EJo4tMiYg0KyWclZxztwO3RzmLxnGLiITBV2dOopsFi4g0y1eFO0nnvIuINMtXhVvjuEVEmuerwp2kBreISLN8Vrh1WVcRkeb4qnBjsHHnfuo0tEREpEm+KtxLN5cC8OistXFOIiLiX74q3NtKKwD405yi+AYREfExXxXutJRAnJLyyjgnERHxL18V7h17qgBITbY4JxER8S9fFe561bX6clJEpCm+LNwiItI0FW4RkQSjwi0ikmB8Vbg7pH4ZR3fCERFpnK8Kd/AJk7U6e1JEpFG+KtzBreyXFmyOYxIREf/yVeEOHgZ484uL2VNZE8c0IiL+5KvC/R8jeh/w/M8fF8UniIiIj/mqcN9/yYgDnu/Yo1PfRUQO5qvCnZp8YJxnPt0QpyQiIv7lq8J9sMvG9I93BBER3/F14U5J0sWmREQO5rvCPXXS0IZpjeQWETmU7wr3lacMaJh+bNY6Kmtq4xdGRMSHfFe4O6Qm8/z3T254PuTWN/hs426dAi8i4vFd4QY4aUC3A55f9PAc/vLJ53FKIyLiL74s3I15dfHWeEcQEfGFhCncn67fGe8IIiK+kDCFW0REAnxbuPt2zThk3pNz1schiYiIv/i2cD919ehD5t3xynJWbiunTtfqFpF2zLeF+6jcLHp0Sj9k/jkPzOIPs9bFIZGIiD/4tnADTDy2Z6PzX/5MN1kQkfbL14X7rguOo1+3Q/u6C7eVxyGNiIg/hFW4zayLmb1gZoVmtsLMTm5+q9ZLSjJm33xmo8sWb9odiwgiIr4Tbov7QeAN59xQYASwInqRDvX2jeMOmXfB7+ewcls5NbV1sYwiIhJ3zRZuM8sGxgGPAzjnqpxzMW3uDurZqdH55zwwi+lvrYplFBGRuAunxT0QKAH+ZGYLzWyGmWUevJKZXWdmBWZWUFJSEvGgp+XlNDr/0Q/Xsr9KVxAUkfYjnMKdAowCHnHOnQDsBaYevJJz7jHnXL5zLj83NzfCMeEXk49pctkvX14a8eOJiPhVOIV7E7DJOTfXe/4CgUIeU8f06tzkshfmb4phEhGR+Gq2cDvntgEbzWyIN+ssYHlUUzXh5R+eyuiDLvlab8eeSmp1RqWItAPhjir5MfC0mS0GRgK/il6kpo3o14W/f7/xkYj597zDFU98qjvmiEibF1bhds595vVfH++cu8g5tyvawUL5yZl5jc7/aM0O7nolLh8GRERixtdnTjblR2cOanLZ03M3xDCJiEjsJWThTktJYkTf7HjHEBGJi4Qs3AA/nTiE9JTG4+/cW8Wijbs1vltE2iSLxt3T8/PzXUFBQcT325hL//Bv5jZxW7PJw3vx8GUxH7koItJiZjbfOZcfzroJ2+Kud+bQHk0ue22JbjAsIm1PwhfuK04ZEO8IIiIxlfCFu0NqcqN3ygm2tXS/xneLSJuR8IUb4J6Ljmty2axVJZx833v89LlFMUwkIhI9baJwTzz2CIqmTea284cdsuzyJz4F4O3l22MdS0QkKtpE4a53Yv+uTS6r0g0XRKSNaFOFe0S/LvGOICISdW2qcAPkh2h1l1dUc+1TBczUMEERSWBtrnD//Xsn89x1Yxk3+NCbOXyybidvL9/OD55eEIdkIiKRkRLvAJGWlGSMOao7GWnJzFp14C3Urn0qNmdziohEU5trcdc7vq/6u0WkbWqzhTscG77YR1lFdbxjiIi0SJsu3K9f/xUAumWmHbJse1kF4377Phf+fk6sY4mItEqbLtzH9OpM0bTJ/PHyEw9ZNu31QgDW79gb61giIq3Spgt3vcbuEP+PhZvjkEREpPXaReHumNb84Jm3l29n+ZayGKQREWmdNjccsClpyUlNnvZeW+cahgoWTZscy1giIi3WLlrcAIV3n8uPz8zjyatOOmTZq4u3xCGRiMjhaTct7qQk42cTh1C679Dhf9c/+1kcEomIHJ520+Kul90xNd4RRERapd0V7uZUVNeyens5W3bvj3cUEZFGtcvCffWpA5tctrW0grN/N4tTpr0Xw0QiIuEz51zEd5qfn+8KCvx9Qacv9lSSkZbMsNvebHIdjTARkVgxs/nOufxw1m03X04erHtW6BsMi4j4VbvsKgnX3sqaeEcQETmECncIxeWVfO3/5nD1k/PiHUVEpEG7L9wPThkJQM/Oh3adjJ/+AQs27Oa9wuJYxxIRaVK77eOud+HIPpxydA45WWkMvGVmvOOIiDSr3be4AXI7pWNmIdfZV6X+bhHxh3bf4g7XBytL2F9VS61zXJLfL95xRKQdC7twm1kyUABsds6dH71I/hR8Z3gVbhGJp5Z0lVwPrIhWED+Yf+sEAL4+qm+ck4iINC2swm1mfYHJwIzoxomv7lnpFE2bzP9cMiLkerv3VcUokYjIocJtcT8A3Aw0ficCwMyuM7MCMysoKSmJSDi/+unfF/HknPX89s3CeEcRkXao2cJtZucDxc65+aHWc8495pzLd87l5+bmRiygH71XWMwdryzn4ffXxjuKiLRD4bS4TwUuMLMi4FngTDP7a1RT+cDsm8fHO4KISKOaLdzOuVucc32dcwOAKcB7zrlvRz1ZnPXr1pFld55D4d3nhlxvTXF5jBKJiAToBJwQMtNT6JCaHHKdCffPYv2OvSzcsCtGqUSkvWvRCTjOuQ+AD6KSJIGNn/4BoOt3i0hsqMUdhnd+Oi7eEUREGqhwhyGvRydm3zyeT245K+R633l8Lv9cuJlb/7kkRslEpD3StUrC1K9bx2bXmb16B7NX7wDgnouGRzuSiLRTanG30OThveIdQUTaORXuFvrdpSPDWm/Omh1RTiIi7ZUKdwulpSSx6PaJLLp9Ysj1Lpsxl7/P28gv/7k0RslEpL1Q4T4M2RmpZGekclyfziHXu/nFxfzlk89xzsUomYi0ByrcrfDkVaPDWm/RptIoJxGR9kSFuxVystKZcXk+//vNE0Kud9HDc1i9vZz5n+vsShFpPRXuVpowrCf/MaI3R+Vmhlzv7N/N4uuPfKxuExFpNRXuCPnj5flhrXftUyGvjisi0iwV7gg5OjeLycf3YnDPLHp2Tm9yvXdWbKe4rILPv9gbw3Qi0pZYND665+fnu4KCgojvN1F8/ZGPw+rPXnLHRDp1SI1BIhHxOzOb75wL66O7WtxR8KPxeWGtN/yOt6isqY1yGhFpa1S4o2D80B506hC4DMxXBuWEXHdbaQXrd6jbRETCp4tMRckH/3UGZRU1/OaN0DcUPv23HwBwaX4/7vvacJKSLAbpRCSRqcUdJd2z0hmYk8nUSUMb5mWlN/138rmCjawp2ROLaCKS4FS4o6x/90y+NeZIAC4Y2TvkuutK9vDi/E0s31IWi2gikqA0qiSGnv10A1NfCu8mC2/dOI7BPTtFOZGI+IVGlfjUpSf1a5i+8pQBIdctKa+MchoRSVT6cjKGzIy3bxzH/M93sb0sdGF+9MO1XDZjLoN6ZPHSD07ReG8RaaAWd4wN6tmJKaOP5Pi+2SHXq78F2uriPby7ojgW0UQkQahwx8n4oT0YekSgD/u284eFXLe8opp/LNzEbS8vpaJaJ+yItHfqKomjf/zgVLaW7ufT9TtDrvfLl5c1TOf1yOLykwdEOZmI+Jla3HGUkZbMUblZfG1U34Z55w0/IuQ2FdW1FJdX8OePi6iurYt2RBHxIRVuH0hLSeLpa8YwemA3LhgReqz3Q++uYfS973L7v5bxxEfrY5RQRPxEXSU+cWpeDqfm5VDTTCt6T2VNw/SufdXs2FPJwg27OWtoD50uL9JOqMXtMynJSXzv9KMAeODSkSHX3bBzL/n3vMO1TxXwxBy1vkXaC7W4fei/zxnKf55+dLMt6JlLtjVMr9pezudf7GXxplLOG96LZLW+RdosFW4fSkoyunRMO2DeUTmZrAtx+dfKmrqGKw2uKd7DjWcPjmZEEYkjdZX4XMGtEzh9cC4zr/9KyPVe/mxLw/TSzaWs37GXRRt36+bEIm2QCrfP5WSl8+erR9MhNZn+3TuGtU1VbR3jp3/AhQ/P4Yk5RdENKCIxp8KdQJ66ejRnDe3B0jvPCble/enyAP9YuIlFG3fz6zcK2VdVE2IrEUkU6uNOIP27Z/L4lSe1aJuaWseFD88BYPX2Pcy4IqyrRoqIjzXb4jazfmb2vpktN7NlZnZ9LIJJaH+7ZgwAf2qmkBduK2+YXrq5lLeXbyfv5zNZGTRfRBJLOF0lNcDPnHPDgLHAD80s9FWRJOpOycuhaNpkxg/tQZ8uGWFts7+6lmufKqCmzjHlsX8D8PhH61XERRJMs4XbObfVObfAmy4HVgB9oh1MwvfQN08A4J6Ljgu5Xun+6obpXfuqWbq5lLtfXc55D82Oaj4RiawWfTlpZgOAE4C5jSy7zswKzKygpKQkMukkLCf270rRtMl8e2x/TsvLCXu78//3IwBq6wJDBmfMXsf8z3dFJaOIRE7YhdvMsoAXgRucc4fczdY595hzLt85l5+bmxvJjNICN587BIBfnHdMi7ab+LsPuee1FXz9kY+BwEk8O/dWRTyfiLReWKNKzCyVQNF+2jn3UnQjSWsc37cLRdMmA4Hx3L99c2VY263avqdhemvpfibc/yFdO6ay8LaJUckpIocvnFElBjwOrHDO3R/9SBIpl+QHbk78+2+d0KLtTr7vPSDQDw7wx1nreHPZtlCbiEgMWXOnRJvZacBsYAlQf83RnzvnZja1TX5+visoKIhYSGm99wq3c/WTLX9NunRMZbdXwNf+6jxmLtlKXo8sjunVOdIRRdo1M5vvnAvrRItmu0qccx8ButRcgjs1L4ehR3TigSkjqal1DV9MNqe+aAP85s1C/vDhOgCKpk3m2U83kJxkXOy17EUkNnTmZDuRnpLMGzeMA6Bw25ffLR+dm8nakqavOhisvmgDlJRXMvWlJQBcnN+P9Tv2UlNbx6CenSKYWkQao8LdDg3q0YnLxhzJ1acNJCcrnRF3vtXifVz/7MIDno+f/gEQaInvq6qhutaRnZEaibgichAV7nYoOcm496vDG55P+9pwzhjSg+yMVI657Y2w9vHx2i8apmetOnDc/vjpH7C9rLJhdIuIRJauDihMGX0kR2R3oENq4O0wZmA3crLSw97+8ic+bZj+eM0OtpdVRjyjiHxJLW5pYGasvncSKUmGmTFg6mst3se3Znx5Um1VTR13vLKMPl0y+OH4vEhGFWnXVLjlAKnJX34I+/l5QxkzsDvD+2Rz1M+bHP3ZpMG3vt4w/cPxeXyy7gvyemS1qDUvIodS4ZYmXTfu6EPmfXjTGQ33tmyJ4Na7+r5FWkeFW8LyyS1n0alDCpnprX/LlO6rZsRdb3HRyN48MKVlZ3WKiL6clDAdkd2hoWg/c+1YfnxmHgt/efZh7WvEXYHhh//8bAvlFdUMmPoa97y6PGJZRdq6Zk95Pxw65b39eHPZNmYu2cpN5wzhtF+/36p9rbl3EmUVNWRnpJKcpJN1pX1pySnvKtwSMe8Vbqeyuo4XF2zinRXFLd7+sjFH8vTcDQCsumcSaSn6QCjtR0SvVSISrjOH9gRg0vBeLN60mzeXbeNvczc0XGWwOfVFG+ClBZuYvWYHA7p35KZzhkYlr0iiUotbom7n3ipG3f32YW//4zPzqK1zlFVUc/eFxxG40rBI26IWt/hKt8w0Hv32KPp168jPX1rCok2lLdr+f99b0zC9t7KWLh1Tyc5I5YYJgyMdVSQhqMUtMVVb56ipq6N0XzWjf/Vuq/Z1ytHdKdxWzpCenXjmurERSigSH/pyUhLClt37efLjIlKTjYffX9vq/V1z2kAmHnsEg3tm0aVjWgQSisSOCrcknIrqWk669x3KK2oisr++XTPYtGs/AL/5+vFccpJu9iD+psItCa22znHKtHcjepXB/t07sreyhrOH9eS+rx0fsf2KRIoKt7QZlTW1DLk1vGuEt8TwPtn8zyUjGKw79ohPqHBLm7JsSynlFTUc3zebYbe9GZVjTL94BF87oQ81dU4n/khcqHBLm1W4rYziskrGDc5tuOJgWkoSVTV1ETvG7f8xjNMH51JVW8fQI3Q3e4kNFW5pF5ZtKWVN8R4uHNmHCx+ew6KNu1l0+8TDuodmUzLTkvn1N47nuXkbuWHCYE7s3zVi+xYJpsIt7c7eyhp27auib9eOzCvayWuLt3LHBcce1l18wvF/l41i0nFHsKeyhm2lFbq7vbSaCreIp3BbGf9YsJmpk4by2Kx13Pd6Ib88fxh3R/gysvXdNd8cfSQ9O6fzvXFHU1Fdy7ode7jiiXnMvnk82RmpVNfVkZ6SHNFjS9ugwi3SCOccdS5wl/sZs9dxz2sruPvCY/nly8ticvzUZKO61vGTswZxw1mDSNKlayWICrdIM5xzlO6vpkvHNJZtKeU//7qAf/3oVKa+uIQ3lm2L+vHrW+idO6TwwU3j2VtZQ58uGSrm7ZgKt8hhqq1zvF9YzFnH9GDxplIufHgOT1yZz4sLNvPa4q1RP36n9BTKK2u48pQB/GLyMazYWkb/7plkZ6RG/dgSXyrcIhFWV+d4dt5Gvn5iH5LNuHfmCsr219C1YyozPlof0yzv/9cZzFu/EzO4YGRvyvbX0KVjKqnJGn+eyFS4RWKoorqW1OQknHN8WrSTvB5ZzFy8lTteWc6VpwzguXkb2V9dG9NMD04ZyfXPfgbA2zeO46YXFtO1YyrTLx7Brn3V1NY5hhzRibKKaiqqaunRuUNM88mhVLhFfKCuzmEGZsbHa3aQ1zOLHp068Js3Clm/Yy+n5uVw6z+XxjsmAGZQXwoenDKSX81cwfaySp7//slUVNfyyAdruferw8nJSmN7WQV5PTT8MdJUuEUSxOtLttK/eybDendm5F1vUVvr+NNVJ/GNR/8NQKcOKRG7YmKsZaYls7cq8Elj7FHdWLBhN1U1ddx0zhBWbC3j1cVbuSS/L1eeMpDzHprNw98axaj+XbjqT/OYOmkox/XJ5vGP1nPusUdwXJ9s1pXsoU/XDDJSkykuryQzPYXisgoy01PITE9hb2UNnTqkkJGajJlRX9sS5Y5JKtwiCe6LPZWkJCeRnZHKwg27SDJjRL8u3PjcZxR9sZe/XTOW7/11PrNWlRwwLj24WErr1Q/hBJhyUj+enbcRgB+OP5p3VxRTuK2cWyYNpaS8khkfrafg1gnkZKUf1rFUuEXamaqaOqpr68hMT2Fr6X4279pP/oBuFG4ro6BoF98e25+n537O/W+touDWCRRuK+fJOUWcPiSXRz5Yy5LNpZyWl8NHa3bE+0dJeEXTJh/WdircIhK2ujpHeWUN2Rmp1NY5Vm0v55henamtc8z/fBejB3bDOcfc9TsZM7AbdQ6em7eRcYNzyMlK576ZKxiYk8l5x/fi+mc+47unDeSY3p05ddp7XH/WIC4/uT8n3vMOw/tkM/3iEZzzwCwAfnHeMdw7cwUAnTukUJagXUIH803hNrNzgQeBZGCGc25aqPVVuEWkNcorqklLSSI9JZnq2joMSDlouGNtXaB2JScZ28sqqKqpo1+3jmzcuY+yimqO7Z3NF3sq2bWviqNzsyjZU8n20kqO7d2ZdTv2UritjLOH9WRbaQXLtgSmN+7cx/srS5g8vBdlFdX8auYKpl88gt37qvjeX+bzs4lDGJiTyaQHZ3PVqQO4+MR+nPfQbMYNzuXBS0fSOSOV5MM8iSqihdvMkoFVwNnAJmAe8E3nXJMXe1DhFhFpmZYU7nBG7I8G1jjn1jnnqoBngQtbE1BERA5fOIW7D7Ax6Pkmb94BzOw6Mysws4KSkpJI5RMRkYNE7BxZ59xjzrl851x+bm5upHYrIiIHCadwbwb6BT3v680TEZE4CKdwzwMGmdlAM0sDpgD/im4sERFpSkpzKzjnaszsR8CbBIYDPuGci82V50VE5BDNFm4A59xMYGaUs4iISBh0AV8RkQQTlVPezawE+PwwN88B/HbBBD9mAuVqCT9mAn/m8mMm8GeuSGbq75wLa0heVAp3a5hZQbhnD8WKHzOBcrWEHzOBP3P5MRP4M1e8MqmrREQkwahwi4gkGD8W7sfiHaARfswEytUSfswE/szlx0zgz1xxyeS7Pm4REQnNjy1uEREJQYVbRCTB+KZwm9m5ZrbSzNaY2dQYHO8JMys2s6VB87qZ2dtmttr7t6s338zsIS/bYjMbFbTNFd76q83silZm6mdm75vZcjNbZmbX+yRXBzP71MwWebnu9OYPNLO53vGf865lg5mle8/XeMsHBO3rFm/+SjM7pzW5vP0lm9lCM3vVR5mKzGyJmX1mZgXevHi/hl3M7AWoaQIhAAAEV0lEQVQzKzSzFWZ2sg8yDfF+R/WPMjO7Id65vP3d6L3Xl5rZM97/gbi/txo45+L+IHANlLXAUUAasAgYFuVjjgNGAUuD5v0GmOpNTwV+7U2fB7wOGDAWmOvN7was8/7t6k13bUWmXsAob7oTgTsPDfNBLgOyvOlUYK53vL8DU7z5jwL/6U3/AHjUm54CPOdND/Ne23RgoPeaJ7fydfwp8DfgVe+5HzIVATkHzYv3a/hn4BpvOg3oEu9MB+VLBrYB/eOdi8D9BtYDGUHvqSv98N5qyBiJnUTgRTsZeDPo+S3ALTE47gAOLNwrgV7edC9gpTf9BwK3aztgPeCbwB+C5h+wXgTyvUzglnG+yQV0BBYAYwicMZZy8GtI4IJkJ3vTKd56dvDrGrzeYWbpC7wLnAm86h0jrpm8fRRxaOGO22sIZBMoROaXTI1knAjM8UMuvrx5TDfvvfIqcI4f3lv1D790lYR1l50Y6Omc2+pNbwN6etNN5Ytabu/j1gkEWrdxz+V1SXwGFANvE2g97HbO1d+aO/gYDcf3lpcC3aOQ6wHgZqDOe97dB5kAHPCWmc03s+u8efF8DQcCJcCfvG6lGWaWGedMB5sCPONNxzWXc24zMB3YAGwl8F6Zjz/eW4CP+rj9xgX+RMZlrKSZZQEvAjc458r8kMs5V+ucG0mglTsaGBrrDMHM7Hyg2Dk3P545mnCac24UMAn4oZmNC14Yh9cwhUC34CPOuROAvQS6IOKZqYHXV3wB8PzBy+KRy+tTv5DAH7zeQCZwbiwzNMcvhdsvd9nZbma9ALx/i735TeWLeG4zSyVQtJ92zr3kl1z1nHO7gfcJfFTsYmb1lwYOPkbD8b3l2cAXEc51KnCBmRURuIH1mcCDcc4ENLTYcM4VA/8g8Icunq/hJmCTc26u9/wFAoXcL++rScAC59x273m8c00A1jvnSpxz1cBLBN5vcX9v1fNL4fbLXXb+BdR/I30FgT7m+vmXe99qjwVKvY9ybwITzayr91d6ojfvsJiZAY8DK5xz9/soV66ZdfGmMwj0u68gUMC/0USu+rzfAN7zWk7/AqZ438IPBAYBnx5OJufcLc65vs65AQTeL+855y6LZyYAM8s0s0710wR+90uJ42vonNsGbDSzId6ss4Dl8cx0kG/yZTdJ/fHjmWsDMNbMOnr/J+t/X3F9bx0gEh3lkXgQ+MZ4FYG+01/E4HjPEOi/qibQIvkugX6pd4HVwDtAN29dAx72si0B8oP2czWwxntc1cpMpxH4WLgY+Mx7nOeDXMcDC71cS4HbvPlHeW/ENQQ+5qZ78zt4z9d4y48K2tcvvLwrgUkRei3P4MtRJXHN5B1/kfdYVv9e9sFrOBIo8F7DfxIYfRHXTN7+Mgm0TrOD5vkh151Aofd+/wuBkSG+eL8753TKu4hIovFLV4mIiIRJhVtEJMGocIuIJBgVbhGRBKPCLSKSYFS4RUQSjAq3iEiC+X+MyHXwAEzcpAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#绘制损失图\n",
    "x_axis = range(len(loss_array))\n",
    "plt.plot(x_axis, loss_array)\n",
    "plt.title('loss for each batch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "object too deep for desired array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-185fb01ec7d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m             {input_text: dyn_input, initial_state: prev_state})\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mpred_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpick_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdyn_seq_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_to_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mgen_sentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-185fb01ec7d2>\u001b[0m in \u001b[0;36mpick_word\u001b[0;34m(probabilities, int_to_vocab)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mint_to_vocab\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m映射表\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     '''\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#根据probably从所有里选50个\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mint_to_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: object too deep for desired array"
     ]
    }
   ],
   "source": [
    "\n",
    "#五.使用模型\n",
    "def get_tensors(loaded_graph):\n",
    "    '''\n",
    "    获取模型训练结果参数\n",
    "    参数\n",
    "    ---\n",
    "    loaded_graph: 从文件加载的tensroflow graph\n",
    "    '''\n",
    "    inputs = loaded_graph.get_tensor_by_name('inputs:0')\n",
    "    initial_state = loaded_graph.get_tensor_by_name('initial_state:0')\n",
    "    final_state = loaded_graph.get_tensor_by_name('final_state:0')\n",
    "    probs = loaded_graph.get_tensor_by_name('probs:0')\n",
    "    return inputs, initial_state, final_state, probs\n",
    "\n",
    "\n",
    "def pick_word(probabilities, int_to_vocab):\n",
    "    '''\n",
    "    选择单词进行文本生成，用来以一定的概率生成下一个词\n",
    "    参数\n",
    "    ---\n",
    "    probabilities: Probabilities of the next word\n",
    "    int_to_vocab: 映射表\n",
    "    '''\n",
    "    result = np.random.choice(len(probabilities), 50, p=probabilities) #根据probably从所有里选50个\n",
    "    return int_to_vocab[result[0]]\n",
    "\n",
    "\n",
    "# 生成文本的长度\n",
    "gen_length = 300\n",
    "\n",
    "# 定义冷启动的单词\n",
    "prime_word = '离开'\n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # 加载模型\n",
    "    loader = tf.train.import_meta_graph(save_dir + '.meta')\n",
    "    loader.restore(sess, save_dir)\n",
    "\n",
    "    # 获取训练的结果参数\n",
    "    input_text, initial_state, final_state, probs = get_tensors(loaded_graph)\n",
    "\n",
    "    # Sentences generation setup\n",
    "    gen_sentences = [prime_word]\n",
    "    prev_state = sess.run(initial_state, {input_text: np.array([[1]])})\n",
    "\n",
    "    # 生成句子\n",
    "    for n in range(gen_length):\n",
    "        dyn_input = [[vocab_to_int[word] for word in gen_sentences[-seq_length:]]]\n",
    "        dyn_seq_length = len(dyn_input[0]) # =1\n",
    "\n",
    "        # 预测\n",
    "        probabilities, prev_state = sess.run(\n",
    "            [probs, final_state],\n",
    "            {input_text: dyn_input, initial_state: prev_state})\n",
    "\n",
    "        pred_word = pick_word(probabilities[dyn_seq_length - 1], int_to_vocab)\n",
    "\n",
    "        gen_sentences.append(pred_word)\n",
    "\n",
    "    lyrics = ' '.join(gen_sentences)\n",
    "    lyrics = lyrics.replace(';', '\\n')\n",
    "    lyrics = lyrics.replace('.', ' ')\n",
    "    lyrics = lyrics.replace(' ', '')\n",
    "\n",
    "    print(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
